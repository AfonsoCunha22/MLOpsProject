# Machine Learning Operations - Song Lyrics Sentiment Analysis
## **Description**
The goal of this project is to perform **sentiment analysis** on **English song lyrics**, filtering out non-English lyrics from the dataset. Sentiment analysis provides insights into the emotional tone of song lyrics, classifying sentiments into five categories: Very Negative, Negative, Neutral, Positive, and Very Positive.

We leverage **Hugging Face** and pre-trained language models for sentiment classification. By employing state-of-the-art tools and best practices in MLOps, we aim to create a scalable and reproducible pipeline for analyzing large datasets of song lyrics.

This project incorporates multiple components of MLOps, including **data versioning**, **experiment tracking**, **pipeline reproducibility**, and **containerization**, ensuring a streamlined and efficient workflow.


## **Frameworks and Tools**
To achieve the project's objectives, we use the following tools and frameworks:

- **Hugging Face**: For building the baseline and utilizing pre-trained sentiment analysis models.
- **DVC (Data Version Control)**: For managing dataset versioning and ensuring data consistency across team members.
- **Weights & Biases (W&B)**: To track experiments, monitor performance metrics, and visualize model training.
- **Hydra**: For configuration management to ensure reproducibility of experiments.
- **Docker**: To containerize the entire pipeline, facilitating portability and deployment across different environments.
- **Streamlit**: For the frontend development
- **Google Cloud**: It provides multiple services that were used, such as the storage, cloud, monitoring, api, etc.


## **Dataset**
The chosen dataset provides a collection of 2000 social media comments extracted from Reddit, Twitter and other platforms where each entry is uniquely identified by an id and includes the full text with the sentiment to be analysed. The 'Sentiment Type' column categorizes each comment into one of three classes: 'positive,' 'negative,' or 'neutral,' indicating the sentiment expressed within the text which simplifies from the previously chosen dataset with 5 labels. This dataset serves as a valuable resource for training and evaluating sentiment analysis models, enabling us to build and refine systems capable of accurately classifying the sentiment expressed in social media content. Given that we were working with a pre-build model, a 2000 rows sized dataset was more than enough to train and evaluate our model.

The processed dataset can be found on Kaggle: [Social Media Sentiment Analysis](https://www.kaggle.com/datasets/abdullah0a/social-media-sentiment-analysis-dataset).


## **Model**
The sentiment analysis in our system leverages the albert-base-v2 model from Google AI, fine-tuned for the task of sentiment classification. This model offers several key advantages:

- Multilingual Proficiency: It excels at handling text in various languages, making it suitable for analyzing social media content from diverse sources.
- Synthetic Data Training: Trained on synthetic multilingual data generated by advanced large language models (LLMs), the model exhibits robustness across different languages and cultural contexts.
- Fine-tuned for Sentiment: The fine-tuning process specifically tailors the model for sentiment analysis, resulting in accurate sentiment classifications.
- Granular Sentiment Labels: It classifies sentiment into three categories: Negative, Neutral, Positive providing a more nuanced understanding of sentiment compared to the traditional three-class categorizations.

By employing the ALBERT model, our system benefits from its ability to handle diverse languages, its robustness due to synthetic data training, and its fine-tuned accuracy for sentiment classification tasks.

---

This project was completed as part of the Machine Learning Operations (MLOps) course 02476 at DTU. The group consists of **Afonso Cunha**, **Lydia Kasapi**, **Sabina Kozlowska**, and **Sandra Gomez**.


## Project structure

The directory structure of the project looks like this:
```txt
├───.dvc
├───.github
│   └───workflows
├───.ruff_cache
│   ├───0.9.2
│   └───content
├───credentials
└───MLOpsProject
    ├───.github
    ├───.ruff_cache
    │   ├───0.9.2
    │   └───content
    ├───configs
    ├───data
    │   ├───processed
    │   └───raw
    ├───dockerFiles
    ├───docs
    │   └───source
    ├───front_end
    ├───log
    │   ├───evaluate
    │   └───train
    ├───logs
    ├───models
    │   └───trained_sentiment_model
    ├───monitoring_exercise_files
    ├───notebooks
    ├───onnx_deployment
    ├───reports
    │   ├───end_report
    │   │   └───figures
    │   └───figures
    ├───results
    │   ├───checkpoint-200
    │   └───checkpoint-400
    ├───src
    │   └───sentiment_analysis
    │       ├───conf
    │       └───__pycache__
    ├───system_monitoring
    ├───tests
    └───wandb
        ├───run-20250117_145405-tf1nfyqh
        │   ├───files
        │   ├───logs
        │   └───tmp
        │       └───code
        ├───run-20250124_124830-apktwyvb
        │   └───files
        └───sweep-n4ns7kix
```


Created using [mlops_template](https://github.com/SkafteNicki/mlops_template),
a [cookiecutter template](https://github.com/cookiecutter/cookiecutter) for getting
started with Machine Learning Operations (MLOps).
